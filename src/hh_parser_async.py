"""
–ú–æ–¥—É–ª—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π —Å hh.ru API.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Å HHParserAsync –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
–æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤.
"""

import aiohttp
import asyncio
from typing import List, Dict, Optional
import json
from aiohttp import ClientSession, TCPConnector
import time
from pathlib import Path


class HHParserAsync:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π —Å HeadHunter API.

    Attributes:
        base_url: –ë–∞–∑–æ–≤—ã–π URL API HH.ru
        headers: HTTP-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
        max_concurrent_requests: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        semaphore: –°–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        request_count: –°—á–µ—Ç—á–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        error_count: –°—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
    """

    def __init__(self, max_concurrent_requests: int = 10, output_dir: str = "./result"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä.

        Args:
            max_concurrent_requests: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.base_url = "https://api.hh.ru/vacancies"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'HH-User-Agent': 'VacancyParser/1.0'
        }
        self.max_concurrent_requests = max_concurrent_requests
        self.semaphore = asyncio.Semaphore(max_concurrent_requests)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.request_count = 0
        self.error_count = 0

    async def fetch(
            self,
            session: ClientSession,
            url: str,
            params: Optional[dict] = None,
            retry_count: int = 3,
            retry_delay: float = 1.0
    ) -> Optional[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π HTTP-–∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.

        Args:
            session: –°–µ—Å—Å–∏—è aiohttp
            url: URL –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            retry_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            retry_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º API –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        async with self.semaphore:
            for attempt in range(retry_count):
                try:
                    self.request_count += 1

                    async with session.get(
                            url,
                            params=params,
                            headers=self.headers,
                            timeout=aiohttp.ClientTimeout(total=30)
                    ) as response:

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ rate limiting
                        if response.status == 429:
                            retry_after = int(response.headers.get('Retry-After', 60))
                            print(f"‚ö†Ô∏è  Rate limit! –ñ–¥–µ–º {retry_after} —Å–µ–∫—É–Ω–¥...")
                            await asyncio.sleep(retry_after)
                            continue

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
                        if response.status == 403:
                            print(f"‚ö†Ô∏è  403 Forbidden –¥–ª—è {url}")
                            self.error_count += 1
                            await asyncio.sleep(retry_delay * (attempt + 1))
                            continue

                        if response.status in (400, 404):
                            return None

                        response.raise_for_status()
                        data = await response.json()
                        await asyncio.sleep(0.1)

                        return data

                except aiohttp.ClientError as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}/{retry_count}: {e}")
                    self.error_count += 1

                    if attempt < retry_count - 1:
                        delay = retry_delay * (2 ** attempt)
                        await asyncio.sleep(delay)
                    else:
                        return None

                except asyncio.TimeoutError:
                    print(f"‚ö†Ô∏è  Timeout –¥–ª—è {url}")
                    if attempt < retry_count - 1:
                        await asyncio.sleep(retry_delay * (attempt + 1))
                    else:
                        return None

                except Exception as e:
                    print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                    return None

            return None

    async def search_vacancies_page(
            self,
            session: ClientSession,
            query: str,
            area: int,
            page: int
    ) -> Optional[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.

        Args:
            session: –°–µ—Å—Å–∏—è aiohttp
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏)
            area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞
            page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        params = {
            'text': query,
            'area': area,
            'page': page,
            'per_page': 100
        }

        return await self.fetch(session, self.base_url, params)

    async def search_all_vacancies(
            self,
            query: str,
            area: int = 1,
            max_pages: int = 20
    ) -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º.

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏)
            area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ (1 - –ú–æ—Å–∫–≤–∞, 2 - –°–ü–±, 113 - –†–æ—Å—Å–∏—è)
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫—Ä–∞—Ç–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
        """
        print(f"üîç –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏: {query}")

        connector = TCPConnector(limit=30, limit_per_host=10, force_close=False)
        timeout = aiohttp.ClientTimeout(total=300, connect=60)

        async with ClientSession(connector=connector, timeout=timeout) as session:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            first_response = await self.search_vacancies_page(session, query, area, 0)

            if not first_response or 'items' not in first_response:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏")
                return []

            all_vacancies = first_response['items']
            total_pages = min(first_response.get('pages', 1), max_pages, 20)
            total_found = first_response.get('found', 0)

            print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {total_found}")
            print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_pages}")

            if total_pages <= 1:
                return all_vacancies

            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            tasks = [
                self.search_vacancies_page(session, query, area, page)
                for page in range(1, total_pages)
            ]

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞–∫–µ—Ç–∞–º–∏
            batch_size = 5
            for i in range(0, len(tasks), batch_size):
                batch = tasks[i:i + batch_size]
                results = await asyncio.gather(*batch)

                for result in results:
                    if result and 'items' in result:
                        all_vacancies.extend(result['items'])

                print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")

                if i + batch_size < len(tasks):
                    await asyncio.sleep(0.5)

            print(f"‚úÖ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
            return all_vacancies

    async def get_vacancy_details(
            self,
            session: ClientSession,
            vacancy_id: str
    ) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏.

        Args:
            session: –°–µ—Å—Å–∏—è aiohttp
            vacancy_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        url = f"https://api.hh.ru/vacancies/{vacancy_id}"
        return await self.fetch(session, url)

    async def get_vacancies_details_batch(
            self,
            vacancy_ids: List[str],
            batch_size: int = 20
    ) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö –ø–∞–∫–µ—Ç–∞–º–∏.

        Args:
            vacancy_ids: –°–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π
            batch_size: –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
        """
        all_details = []
        total = len(vacancy_ids)

        print(f"\nüìã –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è {total} –≤–∞–∫–∞–Ω—Å–∏–π...")

        connector = TCPConnector(limit=30, limit_per_host=10, force_close=False)
        timeout = aiohttp.ClientTimeout(total=300, connect=60)

        async with ClientSession(connector=connector, timeout=timeout) as session:
            for i in range(0, len(vacancy_ids), batch_size):
                batch = vacancy_ids[i:i + batch_size]

                tasks = [
                    self.get_vacancy_details(session, vac_id)
                    for vac_id in batch
                ]

                results = await asyncio.gather(*tasks)
                batch_details = [r for r in results if r is not None]
                all_details.extend(batch_details)

                processed = min(i + batch_size, total)
                percentage = processed / total * 100
                print(f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{total} ({percentage:.1f}%)")

                if i + batch_size < len(vacancy_ids):
                    await asyncio.sleep(1.0)

        return all_details

    async def parse_vacancies(
            self,
            query: str,
            area: int = 1,
            max_vacancies: int = 100
    ) -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π.

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏)
            area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ (1 - –ú–æ—Å–∫–≤–∞, 2 - –°–ü–±, 113 - –†–æ—Å—Å–∏—è)
            max_vacancies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
        """
        start_time = time.time()

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
        vacancies_list = await self.search_all_vacancies(query, area, max_pages=10)

        if not vacancies_list:
            print("‚ùå –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return []

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        vacancies_list = vacancies_list[:max_vacancies]

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        vacancy_ids = [v['id'] for v in vacancies_list]
        detailed_vacancies = await self.get_vacancies_details_batch(vacancy_ids, batch_size=20)

        elapsed_time = time.time() - start_time

        print(f"\n{'=' * 60}")
        print(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(detailed_vacancies)} –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ {len(vacancy_ids)}")
        print(f"üìà –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {self.request_count}")
        print(f"‚ö†Ô∏è  –û—à–∏–±–æ–∫: {self.error_count}")
        print(f"{'=' * 60}\n")

        return detailed_vacancies

    def save_to_json(self, data: any, filename: str) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON-—Ñ–∞–π–ª.

        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        filepath = self.output_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")


def parse_vacancies_async(
        query: str,
        area: int = 1,
        max_vacancies: int = 100,
        max_concurrent: int = 10,
        output_dir: str = "./result"
) -> List[Dict]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏)
        area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ (1 - –ú–æ—Å–∫–≤–∞, 2 - –°–ü–±, 113 - –†–æ—Å—Å–∏—è)
        max_vacancies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è
        max_concurrent: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
    """
    parser = HHParserAsync(max_concurrent_requests=max_concurrent, output_dir=output_dir)

    try:
        loop = asyncio.get_event_loop()
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    vacancies = loop.run_until_complete(
        parser.parse_vacancies(query, area, max_vacancies)
    )

    if vacancies:
        safe_query = query.replace(' ', '_').replace('/', '_').lower()
        parser.save_to_json(vacancies, f'{safe_query}_raw.json')

    return vacancies
