import requests
import time
import json
from typing import List, Dict
from pathlib import Path


class HHParser:
    def __init__(self, output_dir: str = "./result"):
        self.base_url = "https://api.hh.ru/vacancies"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json'
        }
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def search_vacancies(self, query: str, area: int = 1, pages: int = 20) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π
        query: –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
        area: —Ä–µ–≥–∏–æ–Ω (1 - –ú–æ—Å–∫–≤–∞, 2 - –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, 113 - –†–æ—Å—Å–∏—è)
        pages: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        vacancies = []

        for page in range(pages):
            params = {
                'text': query,
                'area': area,
                'page': page,
                'per_page': 100
            }

            try:
                response = requests.get(self.base_url, params=params, headers=self.headers)
                response.raise_for_status()
                data = response.json()

                if 'items' not in data:
                    break

                vacancies.extend(data['items'])
                print(f"üì• –°–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")

                if page >= data['pages'] - 1:
                    break

                time.sleep(0.5)  # –ß—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: {e}")
                break

        return vacancies

    def get_vacancy_details(self, vacancy_id: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        url = f"https://api.hh.ru/vacancies/{vacancy_id}"

        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id}: {e}")
            return {}

    def parse_vacancies(self, query: str, area: int = 1, max_vacancies: int = 100):
        """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        print(f"üîç –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏: {query}")

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π
        vacancies_list = self.search_vacancies(query, area, pages=10)
        vacancies_list = vacancies_list[:max_vacancies]

        print(f"\nüìã –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")
        detailed_vacancies = []

        for i, vacancy in enumerate(vacancies_list, 1):
            details = self.get_vacancy_details(vacancy['id'])
            if details:
                detailed_vacancies.append(details)
                print(f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(vacancies_list)} ({i / len(vacancies_list) * 100:.1f}%)")
                time.sleep(0.2)

        print(f"\n‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(detailed_vacancies)} –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
        return detailed_vacancies

    def save_to_json(self, data: any, filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ JSON"""
        filepath = self.output_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")


def parse_vacancies_sync(query: str, area: int = 1,
                         max_vacancies: int = 100,
                         output_dir: str = "./result") -> List[Dict]:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π
    """
    parser = HHParser(output_dir=output_dir)
    vacancies = parser.parse_vacancies(query, area, max_vacancies)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if vacancies:
        safe_query = query.replace(' ', '_').replace('/', '_').lower()
        parser.save_to_json(vacancies, f'{safe_query}_raw.json')

    return vacancies
