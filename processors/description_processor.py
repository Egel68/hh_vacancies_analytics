"""
–ú–æ–¥—É–ª—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π.
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (Facade pattern).
–°–ª–µ–¥—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø–∞–º Single Responsibility –∏ Dependency Inversion.
"""

from typing import List, Dict
from collections import Counter
import pandas as pd

from core.interfaces import (
    ITextCleaner,
    ITextSectionExtractor,
    IDescriptionProcessor
)
from extractors.item_classifier import VacancyItemClassifier


class VacancyDescriptionProcessor(IDescriptionProcessor):
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–∏—Å–∞–Ω–∏–π –≤–∞–∫–∞–Ω—Å–∏–π.

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –æ—á–∏—Å—Ç–∫–∏ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
    –°–ª–µ–¥—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—É Dependency Inversion - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π, –∞ –Ω–µ –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π.
    –°–ª–µ–¥—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—É Single Responsibility - –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é –ø—Ä–æ—Ü–µ—Å—Å–∞.
    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω Facade - –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫ —Å–ª–æ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ.
    """

    def __init__(
            self,
            text_cleaner: ITextCleaner,
            requirements_extractor: ITextSectionExtractor,
            responsibilities_extractor: ITextSectionExtractor,
            use_classifier: bool = True  # –ù–û–í–´–ô –ü–ê–†–ê–ú–ï–¢–†
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞.

        Args:
            text_cleaner: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML
            requirements_extractor: –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
            responsibilities_extractor: –≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π
            use_classifier: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        """
        self.text_cleaner = text_cleaner
        self.requirements_extractor = requirements_extractor
        self.responsibilities_extractor = responsibilities_extractor
        self.use_classifier = use_classifier

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.classifier = VacancyItemClassifier() if use_classifier else None

        # –•—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processed_data: List[Dict] = []
        self.all_requirements: List[str] = []
        self.all_responsibilities: List[str] = []

    def process_vacancies(self, vacancies: List[Dict]) -> pd.DataFrame:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –≤—Å–µ—Ö –≤–∞–∫–∞–Ω—Å–∏–π.

        Args:
            vacancies: –°–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–ª–µ–º description

        Returns:
            DataFrame —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—è–º–∏
        """
        print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π {len(vacancies)} –≤–∞–∫–∞–Ω—Å–∏–π...")

        # –°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö
        self.processed_data = []
        self.all_requirements = []
        self.all_responsibilities = []

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
        for idx, vacancy in enumerate(vacancies, 1):
            if idx % 50 == 0 or idx == len(vacancies):
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{len(vacancies)}")

            result = self._process_single_vacancy(vacancy)

            if result:
                self.processed_data.append(result)
                self.all_requirements.extend(result['requirements'])
                self.all_responsibilities.extend(result['responsibilities'])

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(set(self.all_requirements))}")
        print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π: {len(set(self.all_responsibilities))}")

        return self._create_dataframe()

    def _process_single_vacancy(self, vacancy: Dict) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏.

        Args:
            vacancy: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–∞–∫–∞–Ω—Å–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–ª–∏ None
        """
        raw_description = vacancy.get('description', '')

        if not raw_description:
            return None

        # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML
        clean_text = self.text_cleaner.clean(raw_description)

        if not clean_text or len(clean_text) < 50:
            return None

        # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        requirements = self.requirements_extractor.extract(clean_text)

        # –®–∞–≥ 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π
        responsibilities = self.responsibilities_extractor.extract(clean_text)

        # ========== –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –°–ú–ï–®–ê–ù–ù–´–• –î–ê–ù–ù–´–• ==========

        if self.use_classifier and self.classifier:
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (–º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏)
            req_filtered, req_misclassified = self.classifier.separate_mixed_items(
                requirements
            )

            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π (–º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
            resp_misclassified, resp_filtered = self.classifier.separate_mixed_items(
                responsibilities
            )

            # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –ø–µ—Ä–µ–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            final_requirements = list(set(req_filtered + resp_misclassified))
            final_responsibilities = list(set(resp_filtered + req_misclassified))
        else:
            final_requirements = requirements
            final_responsibilities = responsibilities

        # ===================================================================

        return {
            'vacancy_id': vacancy.get('id'),
            'vacancy_name': vacancy.get('name'),
            'company': vacancy.get('employer', {}).get('name') if vacancy.get('employer') else None,
            'clean_description': clean_text,
            'requirements': final_requirements,
            'responsibilities': final_responsibilities,
            'requirements_count': len(final_requirements),
            'responsibilities_count': len(final_responsibilities),
        }

    def _create_dataframe(self) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ DataFrame –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        if not self.processed_data:
            return pd.DataFrame()

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è DataFrame (—Å–∫–ª–µ–∏–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤ –≤ —Å—Ç—Ä–æ–∫–∏)
        df_data = []

        for item in self.processed_data:
            df_data.append({
                'vacancy_id': item['vacancy_id'],
                'vacancy_name': item['vacancy_name'],
                'company': item['company'],
                'requirements': '; '.join(item['requirements']) if item['requirements'] else '',
                'responsibilities': '; '.join(item['responsibilities']) if item['responsibilities'] else '',
                'requirements_count': item['requirements_count'],
                'responsibilities_count': item['responsibilities_count'],
            })

        return pd.DataFrame(df_data)

    def get_requirements_frequency(self) -> pd.DataFrame:
        """
        –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π.

        Returns:
            DataFrame —Å —á–∞—Å—Ç–æ—Ç–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        """
        if not self.all_requirements:
            return pd.DataFrame(columns=['–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ', '–ß–∞—Å—Ç–æ—Ç–∞', '–ü—Ä–æ—Ü–µ–Ω—Ç'])

        # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏
        counter = Counter(self.all_requirements)
        total_vacancies = len(self.processed_data)

        freq_data = []
        for requirement, count in counter.most_common(100):  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 100
            freq_data.append({
                '–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ': requirement,
                '–ß–∞—Å—Ç–æ—Ç–∞': count,
                '–ü—Ä–æ—Ü–µ–Ω—Ç': round(count / total_vacancies * 100, 2)
            })

        return pd.DataFrame(freq_data)

    def get_responsibilities_frequency(self) -> pd.DataFrame:
        """
        –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π.

        Returns:
            DataFrame —Å —á–∞—Å—Ç–æ—Ç–æ–π –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π
        """
        if not self.all_responsibilities:
            return pd.DataFrame(columns=['–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å', '–ß–∞—Å—Ç–æ—Ç–∞', '–ü—Ä–æ—Ü–µ–Ω—Ç'])

        # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏
        counter = Counter(self.all_responsibilities)
        total_vacancies = len(self.processed_data)

        freq_data = []
        for responsibility, count in counter.most_common(100):  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 100
            freq_data.append({
                '–û–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å': responsibility,
                '–ß–∞—Å—Ç–æ—Ç–∞': count,
                '–ü—Ä–æ—Ü–µ–Ω—Ç': round(count / total_vacancies * 100, 2)
            })

        return pd.DataFrame(freq_data)

    def get_detailed_vacancy_data(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏.

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        return self.processed_data

    def get_statistics(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        if not self.processed_data:
            return {}

        total_requirements = len(self.all_requirements)
        total_responsibilities = len(self.all_responsibilities)
        unique_requirements = len(set(self.all_requirements))
        unique_responsibilities = len(set(self.all_responsibilities))

        avg_req_per_vacancy = total_requirements / len(self.processed_data) if self.processed_data else 0
        avg_resp_per_vacancy = total_responsibilities / len(self.processed_data) if self.processed_data else 0

        return {
            'total_vacancies_processed': len(self.processed_data),
            'total_requirements_extracted': total_requirements,
            'total_responsibilities_extracted': total_responsibilities,
            'unique_requirements': unique_requirements,
            'unique_responsibilities': unique_responsibilities,
            'avg_requirements_per_vacancy': round(avg_req_per_vacancy, 2),
            'avg_responsibilities_per_vacancy': round(avg_resp_per_vacancy, 2),
            'classifier_used': self.use_classifier
        }
