"""
–ú–æ–¥—É–ª—å –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∫–∞–Ω—Å–∏–π.
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã (Facade pattern).
"""

import json
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd

from core.interfaces import (
    IVacancySearcher,
    IVacancyDetailsFetcher,
    IVacancyAnalyzer,
    IVacancyVisualizer
)
from storage.savers import JsonSaver, CsvSaver


class VacancyPipeline:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∫–∞–Ω—Å–∏–π.

    –†–µ–∞–ª–∏–∑—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω Facade –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Å —Å–∏—Å—Ç–µ–º–æ–π.
    –°–ª–µ–¥—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø—É Open/Closed - –æ—Ç–∫—Ä—ã—Ç –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —á–µ—Ä–µ–∑ DI.
    """

    def __init__(
            self,
            searcher: IVacancySearcher,
            details_fetcher: IVacancyDetailsFetcher,
            analyzer_class: type,
            visualizer: IVacancyVisualizer,
            output_dir: str = "./result"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pipeline.

        Args:
            searcher: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
            details_fetcher: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π
            analyzer_class: –ö–ª–∞—Å—Å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
            visualizer: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            output_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.searcher = searcher
        self.details_fetcher = details_fetcher
        self.analyzer_class = analyzer_class
        self.visualizer = visualizer
        self.output_dir = Path(output_dir)

        self.json_saver = JsonSaver()
        self.csv_saver = CsvSaver()

    def process_single_query(
            self,
            query: str,
            area: int = 1,
            max_vacancies: int = 100,
            show_plots: bool = False,
            tech_keywords: Optional[List[str]] = None
    ) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.

        Args:
            query: –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏
            area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞
            max_vacancies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π
            show_plots: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏
            tech_keywords: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞
        """
        safe_query = query.replace(' ', '_').replace('/', '_').lower()
        output_dir = self.output_dir / safe_query
        output_dir.mkdir(parents=True, exist_ok=True)

        print(f"\n{'=' * 60}")
        print(f"üìä –ê–Ω–∞–ª–∏–∑: {query}")
        print(f"{'=' * 60}")

        # 1. –ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π
        vacancies_list = self.searcher.search(query, area, max_pages=10)

        if not vacancies_list:
            print(f"‚ùå –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è: {query}")
            return {}

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        vacancies_list = vacancies_list[:max_vacancies]

        # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        detailed_vacancies = self.details_fetcher.fetch_details(vacancies_list)

        if not detailed_vacancies:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –¥–ª—è: {query}")
            return {}

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.json_saver.save(
            detailed_vacancies,
            str(output_dir / 'raw.json')
        )

        # 4. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")
        analyzer = self.analyzer_class(detailed_vacancies)
        df = analyzer.extract_data()

        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.csv_saver.save(df, str(output_dir / 'processed.csv'))

        # 6. –ê–Ω–∞–ª–∏–∑ –Ω–∞–≤—ã–∫–æ–≤
        skills_df = analyzer.analyze_skills()
        if len(skills_df) > 0:
            self.csv_saver.save(skills_df, str(output_dir / 'skills.csv'))

        # 7. –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        requirements_df = analyzer.analyze_requirements(tech_keywords)
        if len(requirements_df) > 0:
            self.csv_saver.save(
                requirements_df,
                str(output_dir / 'requirements.csv')
            )

        # 8. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º
        salary_stats = analyzer.get_salary_stats()
        self.json_saver.save(
            salary_stats,
            str(output_dir / 'salary_stats.json')
        )

        # 9. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        self.visualizer.visualize(analyzer, str(output_dir), show_plots)

        # 10. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–≤–æ–¥–∫–∏
        top_skills = (
            skills_df.head(5)['–ù–∞–≤—ã–∫'].tolist()
            if len(skills_df) > 0 else []
        )

        summary = {
            '–î–æ–ª–∂–Ω–æ—Å—Ç—å': query,
            '–í–∞–∫–∞–Ω—Å–∏–π': len(df),
            '–¢–æ–ø-5 –Ω–∞–≤—ã–∫–æ–≤': ', '.join(top_skills),
            '–°—Ä–µ–¥–Ω—è—è –ó–ü (–æ—Ç)': salary_stats.get('avg_from', 'N/A'),
            '–ú–µ–¥–∏–∞–Ω–∞ –ó–ü (–æ—Ç)': salary_stats.get('median_from', 'N/A'),
            '–ü–∞–ø–∫–∞': str(output_dir)
        }

        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è: {query}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: {output_dir}")

        return summary

    def process_batch_queries(
            self,
            queries: List[str],
            area: int = 1,
            max_vacancies: int = 100,
            show_plots: bool = False,
            tech_keywords: Optional[List[str]] = None
    ) -> None:
        """
        –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

        Args:
            queries: –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π
            area: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞
            max_vacancies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π
            show_plots: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏
            tech_keywords: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        print("=" * 60)
        print("üîÑ –ü–ê–ö–ï–¢–ù–´–ô –ê–ù–ê–õ–ò–ó –í–ê–ö–ê–ù–°–ò–ô")
        print("=" * 60)
        print(f"–î–æ–ª–∂–Ω–æ—Å—Ç–∏: {', '.join(queries)}\n")

        summary_list = []

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        for query in queries:
            summary = self.process_single_query(
                query=query,
                area=area,
                max_vacancies=max_vacancies,
                show_plots=show_plots,
                tech_keywords=tech_keywords
            )

            if summary:
                summary_list.append(summary)

        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–π —Å–≤–æ–¥–∫–∏
        if summary_list:
            summary_df = pd.DataFrame(summary_list)
            summary_path = self.output_dir / 'batch_summary.csv'
            self.csv_saver.save(summary_df, str(summary_path))

            print("\n" + "=" * 60)
            print("üìã –û–ë–©–ê–Ø –°–í–û–î–ö–ê")
            print("=" * 60)
            print(summary_df.to_string(index=False))

        print("\n‚úÖ –ü–∞–∫–µ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
