"""
–ú–æ–¥—É–ª—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è.
–£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø v2 —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
"""

import re
from typing import List
from difflib import SequenceMatcher
from core.interfaces import ITextSectionExtractor


class RequirementsExtractor(ITextSectionExtractor):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏–∏."""

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å–µ–∫—Ü–∏–π —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
    REQUIREMENT_HEADERS = [
        r'—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:?',
        r'—Ç—Ä–µ–±—É–µ–º:?',
        r'–º—ã –æ–∂–∏–¥–∞–µ–º:?',
        r'–æ–∂–∏–¥–∞–µ–º –æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:?',
        r'–∫–∞–Ω–¥–∏–¥–∞—Ç –¥–æ–ª–∂–µ–Ω:?',
        r'–Ω–µ–æ–±—Ö–æ–¥–∏–º[–æ—ã–∞]:?',
        r'–Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –Ω–∞–≤—ã–∫–∏:?',
        r'—á—Ç–æ –º—ã –æ–∂–∏–¥–∞–µ–º:?',
        r'—á—Ç–æ –Ω—É–∂–Ω–æ:?',
        r'requirements:?',
        r'must have:?',
        r'qualifications:?',
        r'–Ω–∞–º –≤–∞–∂–Ω–æ:?',
        r'–º—ã –∏—â–µ–º:?',
        r'–∏–¥–µ–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç:?',
        r'–Ω–∞—à –∏–¥–µ–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç:?',
        r'–≤—ã –Ω–∞–º –ø–æ–¥—Ö–æ–¥–∏—Ç–µ:?',
        r'—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:?',
        r'hard skills:?',
        r'–∫–æ–≥–æ –∏—â–µ–º:?',
        r'–Ω–∞—à–∏ –æ–∂–∏–¥–∞–Ω–∏—è:?',
        r'–æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:?',
        r'–¥–ª—è –Ω–∞—Å –≤–∞–∂–Ω–æ:?',
        r'—á—Ç–æ –∂–¥–µ–º:?',
        r'–∂–¥–µ–º –æ—Ç –≤–∞—Å:?',
        r'—á—Ç–æ –∂–¥—ë–º –æ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:?',
        r'—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏:?',
        r'–Ω–∞—à–∏ –ø–æ–∂–µ–ª–∞–Ω–∏—è:?',
        r'—á—Ç–æ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è:?',
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã-–º–∞—Ä–∫–µ—Ä—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ)
    REQUIREMENT_MARKERS = [
        r'\b–æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã\b',
        r'\b–æ–ø—ã—Ç.*?(?:–æ—Ç|–Ω–µ –º–µ–Ω–µ–µ|–±–æ–ª–µ–µ|\d+)',
        r'\b–∑–Ω–∞–Ω–∏–µ\b',
        r'\b–∑–Ω–∞–Ω–∏—è\b',
        r'\b–≤–ª–∞–¥–µ–Ω–∏–µ\b',
        r'\b—É–º–µ–Ω–∏–µ\b',
        r'\b–Ω–∞–≤—ã–∫[–∏–∏]\b',
        r'\b–ø–æ–Ω–∏–º–∞–Ω–∏–µ\b',
        r'\bexperience\b',
        r'\bknowledge\b',
        r'\bunderstanding\b',
        r'\bproficiency\b',
        r'\bfamiliar with\b',
        r'\bexpertise\b',
        r'\b—É–º–µ–µ—Ç\b',
        r'\b–∑–Ω–∞–µ—Ç\b',
        r'\b–∏–º–µ–µ—Ç –æ–ø—ã—Ç\b',
        r'\b–∏–º–µ–µ—à—å\b',
        r'\b–ø–æ–Ω–∏–º–∞–µ—Ç\b',
        r'\b–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\b',
        r'\b–≤—ã—Å—à–µ–µ\b',
        r'\b—É–≤–µ—Ä–µ–Ω–Ω–æ–µ\b',
        r'\b–≥–ª—É–±–æ–∫–æ–µ\b',
        r'\b–±–∞–∑–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ\b',
        r'\b—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ–ø—ã—Ç\b',
        r'\b—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç[—å–∏]\b',
        r'\b–Ω–∞–≤—ã–∫–∏\s+(?:—Ä–∞–±–æ—Ç—ã —Å|–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è|–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏)',
    ]

    # –†–ê–°–®–ò–†–ï–ù–ù–´–ï —Å—Ç–æ–ø-—Å–µ–∫—Ü–∏–∏
    STOP_SECTION_HEADERS = [
        r'(?:—á—Ç–æ )?–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º:?',
        r'—É—Å–ª–æ–≤–∏—è —Ä–∞–±–æ—Ç—ã?:?',
        r'—É—Å–ª–æ–≤–∏—è:?',
        r'we offer:?',
        r'benefits:?',
        r'–æ –∫–æ–º–ø–∞–Ω–∏–∏:?',
        r'–æ –Ω–∞—Å:?',
        r'about (?:us|company):?',
        r'–∑–∞—Ä–ø–ª–∞—Ç–∞:?',
        r'salary:?',
        r'compensation:?',
        r'–±–µ–Ω–µ—Ñ–∏—Ç—ã:?',
        r'–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∂–∏–∑–Ω—å:?',
        r'–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ:?',
        r'–≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã:?',
        r'–ª–æ–∫–∞—Ü–∏—è:?',
        r'location:?',
        r'–æ—Ñ–∏—Å:?',
        r'—Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã:?',
        r'—Å–æ—Ü\.?\s*–ø–∞–∫–µ—Ç:?',
        r'—Ä–∞–∑–≤–∏—Ç–∏–µ:?',
        r'–æ–±—É—á–µ–Ω–∏–µ:?',
        r'–Ω–∞—à–∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:?',
        r'–ø–æ—á–µ–º—É –º—ã:?',
        r'–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å:?',
        r'–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏:?',
        r'–∑–∞–¥–∞—á–∏:?',
        r'responsibilities:?',
        r'–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç:?',
        r'—á–µ–º –∑–∞–Ω–∏–º–∞—Ç—å—Å—è:?',
        r'—á–µ–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –∑–∞–Ω–∏–º–∞—Ç—å—Å—è:?',
        r'–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç —Ä–µ—à–∞—Ç—å:?',
        r'–∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏:?',
    ]

    # –†–ê–°–®–ò–†–ï–ù–ù–´–ï —Å—Ç–æ–ø-—Ñ—Ä–∞–∑—ã –¥–ª—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (—ç—Ç–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏!)
    NOISE_PHRASES = [
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–º–ø–∞–Ω–∏–∏
        r'^–∑–∞\s+\d+\s+(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)',
        r'^–º—ã –ø–æ–º–æ–≥–ª–∏',
        r'–ø–æ–º–æ–≥–ª–∏\s+\d+\+?\s*–∫–æ–º–ø–∞–Ω–∏',
        r'–≤–Ω–µ–¥—Ä–∏—Ç—å\s+—Å–∏—Å—Ç–µ–º–Ω–æ–µ\s+—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ',
        r'–ø–æ–≤—ã—Å–∏—Ç—å\s+—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å',
        r'—Å–æ–∫—Ä–∞—Ç–∏—Ç—å\s+–∑–∞—Ç—Ä–∞—Ç—ã',

        # –ß—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏—è
        r'^–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º',
        r'^—á—Ç–æ –º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º',
        r'^—É—Å–ª–æ–≤–∏—è',
        r'^–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ',
        r'^—Ä–∞–±–æ—Ç–∞ –≤ –æ—Ñ–∏—Å–µ',
        r'^—É–¥–∞–ª[–µ—ë]–Ω–Ω?—ã–π —Ñ–æ—Ä–º–∞—Ç',
        r'^–≥–∏–±—Ä–∏–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç',
        r'^–≥—Ä–∞—Ñ–∏–∫',
        r'^–∑–∞—Ä–ø–ª–∞—Ç–∞',
        r'^–∑/?–ø',
        r'^\d+/\d+',
        r'^–æ—Ñ–∏—Å',
        r'^–ª–æ–∫–∞—Ü–∏—è',
        r'^–¥–º—Å',
        r'^–≤–º—Å',
        r'–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤',
        r'—Ç–∏–º–±–∏–ª–¥–∏–Ω–≥',
        r'–±–µ—Å–ø–ª–∞—Ç–Ω[—ã–æ][–π–µ]',
        r'–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏[—è—é]',
        r'^–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ',
        r'^—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞',
        r'^–∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ',

        # –û –∫–æ–º–ø–∞–Ω–∏–∏
        r'^–æ –∫–æ–º–ø–∞–Ω–∏–∏',
        r'^–Ω–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è',
        r'^–Ω–∞—à–∞ —Ü–µ–ª—å',
        r'^–º—ã (?:—è–≤–ª—è–µ–º—Å—è|–∑–∞–Ω–∏–º–∞–µ–º—Å—è|—Å–æ–∑–¥–∞–µ–º)',
        r'^–∫–æ–º–ø–∞–Ω–∏—è (?:—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è|—Ä–∞–±–æ—Ç–∞–µ—Ç)',

        # –ü—Ä–∏–∑—ã–≤—ã
        r'^–µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ',
        r'^–µ—Å–ª–∏ (?:—Ç–µ–±–µ|–≤–∞–º) –≤–∞–∂–Ω–æ',
        r'^–±—É–¥–µ–º —Ä–∞–¥—ã',
        r'^–∂–¥–µ–º (?:–≤–∞—Å|—Ç–µ–±—è)',
        r'^–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å',

        # –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
        r'^—É–Ω–∏–∫–∞–ª—å–Ω',
        r'^–æ—Ç–ª–∏—á–Ω',
        r'^–ø—Ä–µ–∫—Ä–∞—Å–Ω',
        r'^–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç',
        r'^–∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ä–æ—Å—Ç',
        r'^–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å (?:—Ä–∞–∑–≤–∏—Ç–∏—è|—Ä–æ—Å—Ç–∞)',
        r'^–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã',
        r'^–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω[–∞—ã][—è–π] –∑–∞—Ä–ø–ª–∞—Ç',
        r'^–∫–æ–º—Ñ–æ—Ä—Ç–Ω[–∞—ã][—è–π]',
        r'^–¥—Ä—É–∂–Ω[–∞—ã][—è–π] –∫–æ–º–∞–Ω–¥',
        r'^—Ä–∞–±–æ—Ç–∞ –≤ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—é—â–µ–π—Å—è',

        # –°–ª–∏—à–∫–æ–º –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã
        r'^–º—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤',
        r'^–∏–¥–µ–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç',
        r'^–≤—ã –Ω–∞–º –ø–æ–¥—Ö–æ–¥–∏—Ç–µ',
        r'^–Ω–∞—à –∏–¥–µ–∞–ª—å–Ω—ã–π',

        # –í–ê–ñ–ù–û: –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏, –ø–æ–ø–∞–≤—à–∏–µ –≤ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (–∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤—ã –∏ –æ—Ç–≥–ª–∞–≥–æ–ª—å–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ)
        r'^—Å–±–æ—Ä –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏',
        r'^—Å–±–æ—Ä –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ',
        r'^—Å–±–æ—Ä —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π',
        r'^—Å–±–æ—Ä,?\s+(?:–∞–Ω–∞–ª–∏–∑|–∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è)',
        r'^–ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ',
        r'^–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –∫–æ–º–∞–Ω–¥–æ–π',
        r'^–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å\s+',
        r'^–æ–ø–∏—Å–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑',
        r'^—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è',
        r'^—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ü–µ–Ω–∫–∞',
        r'^—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞\s+(?:–∏|–±–∏–∑–Ω–µ—Å|–ø—Ä–æ–µ–∫—Ç–Ω—ã—Ö|—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö)',
        r'^–≤–µ–¥–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π',
        r'^–≤–µ–¥–µ–Ω–∏–µ\s+',
        r'^—É—á–∞—Å—Ç–∏–µ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ',
        r'^—É—á–∞—Å—Ç–∏–µ –≤\s+',
        r'^–∞–Ω–∞–ª–∏–∑ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö',
        r'^–∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è',
        r'^–∞–Ω–∞–ª–∏–∑ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤',
        r'^–∞–Ω–∞–ª–∏–∑,?\s+(?:–æ–ø–∏—Å–∞–Ω–∏–µ|—Ç–µ–∫—É—â)',
        r'^–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π',
        r'^–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ',
        r'^–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∑–∞–¥–∞—á',
        r'^–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞\s+(?:–∏|–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π|–æ—Ç—á–µ—Ç)',
        r'^—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞',
        r'^—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ\s+(?:–∏|–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π|—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π)',
        r'^—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á',
        r'^—Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è',
        r'^–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã',
        r'^–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ\s+(?:–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö|–¥–∞—à–±–æ—Ä–¥)',
        r'^—Ä–∞–±–æ—Ç–∞ —Å SQL-–∑–∞–ø—Ä–æ—Å–∞–º–∏',
        r'^—Ä–∞–±–æ—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏',
        r'^—Ä–∞–±–æ—Ç–∞ —Å\s+(?:–±–∞–∑–∞–º–∏|–¥–∞–Ω–Ω—ã–º–∏|–æ—Ç—á–µ—Ç)',
        r'^–∫–æ–Ω—Ç—Ä–æ–ª—å –ª–æ–≥–∏–∫–∏',
        r'^–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ\s+',
        r'^–ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑',
        r'^–ø–æ–∏—Å–∫ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ',
        r'^–ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤',
        r'^–Ω–∞—Å—Ç—Ä–æ–π–∫–∞\s+',
        r'^–≤—ã—è–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π',
        r'^–≤—ã—è–≤–ª–µ–Ω–∏–µ\s+',
        r'^—Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é',
        r'^—Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ\s+',
        r'^—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—ç–∫–ª–æ–≥–æ–º',
        r'^–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ',
        r'^–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ,?\s+–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ',
        r'^–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ,?\s+–∞–Ω–∞–ª–∏–∑',
        r'^–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–Ω–æ',
        r'^–∫—Ä–æ—Å—Å-—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ',
        r'^—Ç–µ—Å–Ω–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å',
        r'^–¥–µ—Ç–∞–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å',
        r'^–∞–∫—Ç–∏–≤–Ω–æ —É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å',

        # –ó–∞–¥–∞—á–∏ –∏–∑ —Å–µ–∫—Ü–∏–∏ "–ß–µ–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç –∑–∞–Ω–∏–º–∞—Ç—å—Å—è"
        r'^—á–µ–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç',
        r'^–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç',
        r'^–∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏',
        r'^–ø—Ä–∏–º–µ—Ä—ã –∑–∞–¥–∞—á',

        # –≠–º–æ–¥–∑–∏
        r'üì©|üìß|‚úâÔ∏è|üíº|üéØ|üöÄ|‚≠ê|‚ú®|üîç|üìä|üìà|üí∞|üèÜ',
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π (–≥–ª–∞–≥–æ–ª—ã –≤ –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤–µ)
    RESPONSIBILITY_VERB_PATTERNS = [
        r'^(?:—Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å|—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞|—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å)',
        r'^(?:–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å|–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)',
        r'^(?:–≤–Ω–µ–¥—Ä—è—Ç—å|–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ|–≤–Ω–µ–¥—Ä–∏—Ç—å)',
        r'^(?:–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å|–ø–æ–¥–¥–µ—Ä–∂–∫–∞)',
        r'^(?:–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å|–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)',
        r'^(?:–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å|–∞–Ω–∞–ª–∏–∑)\s+(?:–¥–∞–Ω–Ω—ã—Ö|–ø—Ä–æ—Ü–µ—Å—Å|—Ç–µ–∫—É—â|–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥|–∫–æ–º–º–µ—Ä—á–µ—Å–∫)',
        r'^(?:—Å–æ–±–∏—Ä–∞—Ç—å|—Å–±–æ—Ä)\s+(?:—Ç—Ä–µ–±–æ–≤–∞–Ω–∏|–¥–∞–Ω–Ω—ã—Ö|–æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏)',
        r'^(?:—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å|—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ)\s+(?:–∏|–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏|—Ç—Ä–µ–±–æ–≤–∞–Ω–∏)',
        r'^(?:—Å–æ–∑–¥–∞–≤–∞—Ç—å|—Å–æ–∑–¥–∞–Ω–∏–µ)',
        r'^(?:—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å|—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)',
        r'^(?:–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞|–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å)\s+(?:–∏|–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏|–æ—Ç—á–µ—Ç|–∑–∞–¥–∞—á)',
        r'^(?:—É—á–∞—Å—Ç–∏–µ|—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å)\s+–≤',
        r'^(?:–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ|–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å)\s+—Å',
        r'^(?:—Ä–∞–±–æ—Ç–∞)\s+—Å\s+(?:–º–µ—Ç—Ä–∏–∫–∞–º–∏|sql|–±–∞–∑–∞–º–∏|–¥–∞–Ω–Ω—ã–º–∏)',
        r'^(?:–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ|–æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å)',
        r'^(?:–∫–æ–Ω—Ç—Ä–æ–ª—å|–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å)',
        r'^(?:–≤–µ–¥–µ–Ω–∏–µ|–≤–µ—Å—Ç–∏)',
        r'^(?:–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ|–ø–æ—Å—Ç—Ä–æ–∏—Ç—å)',
        r'^(?:–≤—ã—è–≤–ª–µ–Ω–∏–µ|–≤—ã—è–≤–ª—è—Ç—å)',
        r'^(?:–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ|–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å)',
        r'^(?:–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ|–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å)',
        r'^(?:–æ–ø–∏—Å–∞–Ω–∏–µ|–æ–ø–∏—Å—ã–≤–∞—Ç—å)',
        r'^(?:—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è|—Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å)',
        r'^(?:–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è|–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å)',
        r'^(?:–Ω–∞—Å—Ç—Ä–æ–π–∫–∞|–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å)',
        r'^(?:—Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ|—Å–æ—Å—Ç–∞–≤–ª—è—Ç—å)',
        r'^(?:—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ|—É–ø—Ä–∞–≤–ª—è—Ç—å)',
        r'^(?:–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ|–æ–±—Å–ª–µ–¥–æ–≤–∞—Ç—å)',
        r'^(?:–ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ|–ø—Ä–æ–≤–æ–¥–∏—Ç—å)',
    ]

    def __init__(
            self,
            min_length: int = 15,
            max_length: int = 400,
            min_words: int = 3,
            similarity_threshold: float = 0.85
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞."""
        self.min_length = min_length
        self.max_length = max_length
        self.min_words = min_words
        self.similarity_threshold = similarity_threshold
        self._compile_patterns()

    def _compile_patterns(self):
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π."""
        self.header_pattern = re.compile(
            r'(?:^|\n)\s*(?:' + '|'.join(self.REQUIREMENT_HEADERS) + r')\s*(?:\n|$)',
            re.IGNORECASE | re.MULTILINE | re.UNICODE
        )
        self.marker_pattern = re.compile(
            r'\b(?:' + '|'.join(self.REQUIREMENT_MARKERS) + r')',
            re.IGNORECASE | re.UNICODE
        )
        self.stop_section_pattern = re.compile(
            r'(?:^|\n)\s*(?:' + '|'.join(self.STOP_SECTION_HEADERS) + r')',
            re.IGNORECASE | re.MULTILINE | re.UNICODE
        )
        self.noise_pattern = re.compile(
            '|'.join(self.NOISE_PHRASES),
            re.IGNORECASE | re.UNICODE
        )
        self.responsibility_verb_pattern = re.compile(
            '|'.join(self.RESPONSIBILITY_VERB_PATTERNS),
            re.IGNORECASE | re.UNICODE
        )

    def extract(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return []

        requirements = []

        # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º —Å–µ–∫—Ü–∏–π (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π)
        section_requirements = self._extract_from_sections(text)
        requirements.extend(section_requirements)

        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º –≤ —Ç–µ–∫—Å—Ç–µ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ —Å–µ–∫—Ü–∏–π)
        if len(section_requirements) < 3:
            marker_requirements = self._extract_by_markers(text)
            requirements.extend(marker_requirements)

        # –ú–µ—Ç–æ–¥ 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
        if len(requirements) < 5:
            list_requirements = self._extract_from_lists(text)
            requirements.extend(list_requirements)

        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        requirements = self._advanced_clean_and_deduplicate(requirements)

        return requirements

    def _extract_from_sections(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∏–∑ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Å–µ–∫—Ü–∏–π."""
        requirements = []

        for match in self.header_pattern.finditer(text):
            section_start = match.end()
            section_end = self._find_section_end(text, section_start)

            if section_end is None:
                section_end = len(text)

            section_text = text[section_start:section_end]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å—Ç–æ–ø-—Å–µ–∫—Ü–∏—è
            if not self.stop_section_pattern.search(match.group()):
                items = self._split_into_items(section_text)
                requirements.extend(items)

        return requirements

    def _find_section_end(self, text: str, start_pos: int) -> int:
        """–ü–æ–∏—Å–∫ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—É—â–µ–π —Å–µ–∫—Ü–∏–∏."""
        next_headers_pattern = re.compile(
            r'\n\s*(?:'
            r'–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏|'
            r'–∑–∞–¥–∞—á–∏|'
            r'responsibilities|'
            r'—É—Å–ª–æ–≤–∏—è|'
            r'–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º|'
            r'what we offer|'
            r'benefits|'
            r'–æ –∫–æ–º–ø–∞–Ω–∏–∏|'
            r'—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è|'
            r'requirements|'
            r'–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç|'
            r'—á–µ–º –∑–∞–Ω–∏–º–∞—Ç—å—Å—è|'
            r'—á–µ–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç|'
            r'–∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏'
            r'):',
            re.IGNORECASE | re.UNICODE
        )

        match = next_headers_pattern.search(text[start_pos:])

        if match:
            return start_pos + match.start()

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–µ–∫—Ü–∏—é 1500 —Å–∏–º–≤–æ–ª–∞–º–∏, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        return min(start_pos + 1500, len(text))

    def _extract_by_markers(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–∞—Ä–∫–µ—Ä–∞–º."""
        requirements = []
        sentences = re.split(r'[.;!?]\s+', text)

        for sentence in sentences:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á)
            if len(sentence) > 300:
                continue

            if self.marker_pattern.search(sentence):
                cleaned = sentence.strip()

                if self._is_valid_requirement(cleaned):
                    requirements.append(cleaned)

        return requirements

    def _extract_from_lists(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤."""
        requirements = []

        list_patterns = [
            r'^[-‚Ä¢*]\s*(.+)$',
            r'^\d+[\.)]\s*(.+)$',
        ]

        lines = text.split('\n')

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–≤ –∫–∞–∫–æ–π —Å–µ–∫—Ü–∏–∏ –Ω–∞—Ö–æ–¥–∏–º—Å—è)
        in_requirements_section = False

        for line in lines:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –º—ã –≤ —Å–µ–∫—Ü–∏—é —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
            if re.search(r'(?:—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è|–º—ã –æ–∂–∏–¥–∞–µ–º|–Ω–∞–º –≤–∞–∂–Ω–æ|—á—Ç–æ –∂–¥–µ–º):', line.lower()):
                in_requirements_section = True
            elif re.search(r'(?:–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏|–∑–∞–¥–∞—á–∏|–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç|—á–µ–º –∑–∞–Ω–∏–º–∞—Ç—å—Å—è):', line.lower()):
                in_requirements_section = False

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ —Ç–æ–ª—å–∫–æ –∏–∑ —Å–µ–∫—Ü–∏–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
            if in_requirements_section:
                for pattern in list_patterns:
                    match = re.match(pattern, line.strip())

                    if match:
                        item = match.group(1).strip()

                        if self._is_valid_requirement(item):
                            requirements.append(item)
                        break

        return requirements

    def _split_into_items(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."""
        items = []

        # –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —è–≤–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
        separators = [';', '\n']
        current_items = [text]

        for sep in separators:
            new_items = []
            for item in current_items:
                parts = item.split(sep)
                new_items.extend(parts)
            current_items = new_items

        # –†–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Ç–æ—á–∫–µ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏ –∑–∞–≥–ª–∞–≤–Ω–∞—è –±—É–∫–≤–∞)
        final_items = []
        for item in current_items:
            parts = re.split(r'\.\s+(?=[–ê-–ØA-Z–Å])', item)
            final_items.extend(parts)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç
        for item in final_items:
            cleaned = self._clean_item(item)

            if self._is_valid_requirement(cleaned):
                items.append(cleaned)

        return items

    def _clean_item(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞."""
        # –£–¥–∞–ª–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏
        text = re.sub(r'[\U0001F300-\U0001F9FF]', '', text)

        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ —Å–ø–∏—Å–∫–æ–≤
        text = re.sub(r'^[-‚Ä¢*\d+\.)]\s*', '', text)

        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        text = ' '.join(text.split())

        # –£–¥–∞–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π –∏ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ
        text = text.rstrip(';').rstrip('.')

        return text.strip()

    def _is_valid_requirement(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è."""
        if not text:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
        if len(text) < self.min_length or len(text) > self.max_length:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤
        words = text.split()
        if len(words) < self.min_words:
            return False

        # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        if text.strip().endswith(':'):
            return False

        # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–æ–ø-—Ñ—Ä–∞–∑
        if self.noise_pattern.search(text):
            return False

        # –í–ê–ñ–ù–û: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≥–ª–∞–≥–æ–ª–æ–≤ –∏ –æ—Ç–≥–ª–∞–≥–æ–ª—å–Ω—ã—Ö —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö (—ç—Ç–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏!)
        if self.responsibility_verb_pattern.search(text):
            return False

        # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if re.match(r'^\d+[\s\-/]*\d*$', text.strip()):
            return False

        # –ò—Å–∫–ª—é—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –æ–±—â–∏—Ö —Ñ—Ä–∞–∑
        generic_phrases = [
            '–º—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤',
            '–∏–¥–µ–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç',
            '–≤—ã –Ω–∞–º –ø–æ–¥—Ö–æ–¥–∏—Ç–µ',
            '–Ω–∞—à –∏–¥–µ–∞–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç',
        ]

        text_lower = text.lower()
        for phrase in generic_phrases:
            if phrase in text_lower:
                return False

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∏–Ω—Ñ–∏–Ω–∏—Ç–∏–≤–∞ - —ç—Ç–æ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å
        infinitive_starts = [
            '—Å–æ–±–∏—Ä–∞—Ç—å', '—Å–±–æ—Ä',
            '–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å', '–∞–Ω–∞–ª–∏–∑',
            '—Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞',
            '—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å', '—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ',
            '–ø—Ä–æ–≤–æ–¥–∏—Ç—å', '–ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ',
            '–ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—Ç—å', '–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞',
            '—Å–æ–∑–¥–∞–≤–∞—Ç—å', '—Å–æ–∑–¥–∞–Ω–∏–µ',
            '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å', '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ',
            '—É—á–∞—Å—Ç–≤–æ–≤–∞—Ç—å', '—É—á–∞—Å—Ç–∏–µ',
            '–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å', '–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ',
            '–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å', '–∫–æ–Ω—Ç—Ä–æ–ª—å',
            '–æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å', '–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ',
            '–≤—ã—è–≤–ª—è—Ç—å', '–≤—ã—è–≤–ª–µ–Ω–∏–µ',
            '–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å', '–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ',
            '–æ–ø–∏—Å—ã–≤–∞—Ç—å', '–æ–ø–∏—Å–∞–Ω–∏–µ',
            '—Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å', '—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è',
            '–≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å', '–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è',
            '–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å', '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞',
            '—Å–æ—Å—Ç–∞–≤–ª—è—Ç—å', '—Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ',
            '–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å', '–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ',
            '–æ–±—Å–ª–µ–¥–æ–≤–∞—Ç—å', '–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ',
        ]

        first_word = text_lower.split()[0] if text_lower.split() else ''
        if any(first_word.startswith(verb) for verb in infinitive_starts):
            return False

        return True

    def _advanced_clean_and_deduplicate(self, requirements: List[str]) -> List[str]:
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è."""
        if not requirements:
            return []

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        cleaned = [req for req in requirements if self._is_valid_requirement(req)]

        unique_requirements = []
        seen_normalized = set()

        for req in cleaned:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            normalized = self._normalize_for_comparison(req)

            if normalized in seen_normalized:
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏
            is_duplicate = False

            for existing in unique_requirements:
                similarity = self._calculate_similarity(req, existing)

                if similarity >= self.similarity_threshold:
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
                    if len(req) > len(existing):
                        unique_requirements.remove(existing)
                        seen_normalized.discard(self._normalize_for_comparison(existing))
                        break
                    else:
                        is_duplicate = True
                        break

            if not is_duplicate:
                unique_requirements.append(req)
                seen_normalized.add(normalized)

        return unique_requirements

    def _normalize_for_comparison(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()

        # –£–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
        text = text.rstrip('.;,')

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
        text = ' '.join(text.split())

        # –£–¥–∞–ª–µ–Ω–∏–µ —á–∞—Å—Ç—ã—Ö –≤–≤–æ–¥–Ω—ã—Ö —Å–ª–æ–≤
        text = re.sub(r'^(?:–æ–ø—ã—Ç\s+)?(?:—Ä–∞–±–æ—Ç—ã\s+)?', '', text)

        return text

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–≤—É—Ö —Å—Ç—Ä–æ–∫."""
        norm1 = self._normalize_for_comparison(text1)
        norm2 = self._normalize_for_comparison(text2)

        return SequenceMatcher(None, norm1, norm2).ratio()


class SkillsBasedRequirementsExtractor(RequirementsExtractor):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏."""

    def __init__(
            self,
            tech_keywords: List[str],
            min_length: int = 15,
            max_length: int = 400,
            min_words: int = 3,
            similarity_threshold: float = 0.85
    ):
        super().__init__(min_length, max_length, min_words, similarity_threshold)
        self.tech_keywords = [kw.lower() for kw in tech_keywords]

    def extract(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π."""
        base_requirements = super().extract(text)

        tech_requirements = []
        other_requirements = []

        for req in base_requirements:
            req_lower = req.lower()

            if any(kw in req_lower for kw in self.tech_keywords):
                tech_requirements.append(req)
            else:
                other_requirements.append(req)

        return tech_requirements + other_requirements

    def get_tech_requirements_only(self, text: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π."""
        all_requirements = super().extract(text)

        return [
            req for req in all_requirements
            if any(kw in req.lower() for kw in self.tech_keywords)
        ]
