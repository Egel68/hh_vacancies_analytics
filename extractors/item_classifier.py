"""
–ú–æ–¥—É–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
–£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —à—É–º–∞.
"""

import re
from typing import List, Tuple
from enum import Enum


class ItemType(Enum):
    """–¢–∏–ø —ç–ª–µ–º–µ–Ω—Ç–∞."""
    REQUIREMENT = "requirement"
    RESPONSIBILITY = "responsibility"
    NOISE = "noise"  # –ù–û–í–û–ï: —à—É–º/–Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    UNKNOWN = "unknown"


class VacancyItemClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π.

    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å—é –∏–ª–∏ —à—É–º–æ–º.
    """

    # ========== –ü–ê–¢–¢–ï–†–ù–´ –î–õ–Ø –®–£–ú–ê (–ù–û–í–û–ï) ==========
    NOISE_PATTERNS = [
        # –ß—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∫–æ–º–ø–∞–Ω–∏—è
        r'\b(?:–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º|we offer|—á—Ç–æ –º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º)',
        r'\b(?:—É—Å–ª–æ–≤–∏—è —Ä–∞–±–æ—Ç—ã|—É—Å–ª–æ–≤–∏—è|benefits)',
        r'\b(?:–∑–∞—Ä–ø–ª–∞—Ç–∞|salary|–∑/?–ø|–æ–∫–ª–∞–¥)',
        r'\b(?:–æ—Ç|–¥–æ)\s+\d+\s*(?:000|—Ç—ã—Å|—Ç—ã—Å—è—á|‚ÇΩ|—Ä—É–±)',
        r'\b(?:–±–µ–Ω–µ—Ñ–∏—Ç—ã|–ª—å–≥–æ—Ç—ã|–∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏)',
        r'\b(?:–¥–º—Å|–≤–º—Å|–æ–º—Å)',
        r'\b(?:–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤|—Ç–∏–º–±–∏–ª–¥–∏–Ω–≥)',
        r'\b(?:–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç|–∫–∞—Ä—å–µ—Ä–Ω—ã–π —Ä–æ—Å—Ç)',
        r'\b(?:–æ–±—É—á–µ–Ω–∏–µ|—Ç—Ä–µ–Ω–∏–Ω–≥–∏|–∫—É—Ä—Å—ã)\s+(?:–∑–∞ —Å—á–µ—Ç|–±–µ—Å–ø–ª–∞—Ç–Ω)',
        r'\b(?:–∫–æ–º—Ñ–æ—Ä—Ç–Ω[–∞—ã][—è–π]|—É–¥–æ–±–Ω[–∞—ã][—è–π])\s+(?:–æ—Ñ–∏—Å|—Å—Ä–µ–¥–∞|–∞—Ç–º–æ—Å—Ñ–µ—Ä–∞)',
        r'\b(?:–≥–∏–±–∫–∏–π –≥—Ä–∞—Ñ–∏–∫|—É–¥–∞–ª–µ–Ω–Ω[–∞—ã][—è–π] —Ä–∞–±–æ—Ç[–∞—ã]|–≥–∏–±—Ä–∏–¥)',
        r'\b(?:–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ|—Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ)',
        r'\b(?:—Å–æ—Ü[\.\s]*–ø–∞–∫–µ—Ç|—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π –ø–∞–∫–µ—Ç)',

        # –û –∫–æ–º–ø–∞–Ω–∏–∏
        r'\b(?:–æ –∫–æ–º–ø–∞–Ω–∏–∏|–æ –Ω–∞—Å|about us|–Ω–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è)',
        r'\b(?:–Ω–∞—à–∞ —Ü–µ–ª—å|–Ω–∞—à–∞ –º–∏—Å—Å–∏—è|–Ω–∞—à–µ –≤–∏–¥–µ–Ω–∏–µ)',
        r'\b(?:–º—ã (?:—è–≤–ª—è–µ–º—Å—è|–∑–∞–Ω–∏–º–∞–µ–º—Å—è|—Å–æ–∑–¥–∞–µ–º))',
        r'\b(?:–∫–æ–º–ø–∞–Ω–∏—è (?:—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è|—Ä–∞–±–æ—Ç–∞–µ—Ç|–∑–∞–Ω–∏–º–∞–µ—Ç—Å—è))',

        # –ü—Ä–∏–∑—ã–≤—ã –∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥
        r'\b(?:–µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ|–µ—Å–ª–∏ (?:—Ç–µ–±–µ|–≤–∞–º) –≤–∞–∂–Ω–æ)',
        r'\b(?:–±—É–¥–µ–º —Ä–∞–¥—ã|–∂–¥–µ–º (?:–≤–∞—Å|—Ç–µ–±—è)|–ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å)',
        r'\b(?:–æ—Ç–∫–ª–∏–∫–∞–π—Ç–µ—Å—å|–∑–≤–æ–Ω–∏—Ç–µ|–ø–∏—à–∏—Ç–µ)',
        r'üì©|üìß|‚úâÔ∏è|üíº|üéØ|üöÄ|‚≠ê|‚ú®',  # –≠–º–æ–¥–∑–∏

        # –û–±—â–∏–µ —Ñ—Ä–∞–∑—ã
        r'^\s*(?:—É–Ω–∏–∫–∞–ª—å–Ω[–∞—ã][—è–π]|–æ—Ç–ª–∏—á–Ω[–∞—ã][—è–π]|–ø—Ä–µ–∫—Ä–∞—Å–Ω[–∞—ã][—è–π])',
        r'\b(?:–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å|–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã)\s+(?:—Ä–∞–∑–≤–∏—Ç–∏—è|—Ä–æ—Å—Ç–∞|–∫–∞—Ä—å–µ—Ä—ã)',
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¢–†–ï–ë–û–í–ê–ù–ò–ô (—É–ª—É—á—à–µ–Ω–Ω—ã–µ)
    REQUIREMENT_PATTERNS = [
        r'\b(?:–æ–ø—ã—Ç|experience)\s+(?:—Ä–∞–±–æ—Ç—ã|–æ—Ç|–Ω–µ –º–µ–Ω–µ–µ|–±–æ–ª–µ–µ|\d+)',
        r'\b(?:–∑–Ω–∞–Ω–∏–µ|–∑–Ω–∞–Ω–∏—è|knowledge of)\s+(?:[–ê-–ØA-Z]|\w+)',
        r'\b(?:–≤–ª–∞–¥–µ–Ω–∏–µ|proficiency|mastery)\s+',
        r'\b(?:—É–º–µ–Ω–∏–µ|–Ω–∞–≤—ã–∫[–∏–∏]?|skill[s]?|ability)\s+',
        r'\b(?:–ø–æ–Ω–∏–º–∞–Ω–∏–µ|understanding)\s+(?:–ø—Ä–∏–Ω—Ü–∏–ø–æ–≤|–æ—Å–Ω–æ–≤|—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π)',
        r'\b(?:–≤—ã—Å—à–µ–µ|—Å—Ä–µ–¥–Ω–µ–µ)\s+–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ',
        r'\b(?:—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç|certification)',
        r'\b(?:english|–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)\s+(?:—è–∑—ã–∫|–Ω–µ –Ω–∏–∂–µ|–æ—Ç|–Ω–∞ —É—Ä–æ–≤–Ω–µ)',
        r'\b–æ—Ç\s+\d+\s+(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)\b',
        r'\b\d+\+?\s+(?:–ª–µ—Ç|–≥–æ–¥–∞|–≥–æ–¥)\s+(?:–æ–ø—ã—Ç|—Ä–∞–±–æ—Ç—ã)',
        r'\b(?:must have|nice to have|required|preferred)\b',
        r'\b(?:–∂–µ–ª–∞—Ç–µ–ª[—å–Ω]|–æ–±—è–∑–∞—Ç–µ–ª[—å–Ω]|–Ω–µ–æ–±—Ö–æ–¥–∏–º[–æ—ã])\b',
        r'\b(?:—É–≤–µ—Ä–µ–Ω–Ω[–æ—ã][–µ–π]|–≥–ª—É–±–æ–∫[–æ–∏–µ][–µ–π])\s+(?:–∑–Ω–∞–Ω–∏–µ|–≤–ª–∞–¥–µ–Ω–∏–µ|–ø–æ–Ω–∏–º–∞–Ω–∏–µ)',
        r'\b(?:–±—É–¥–µ—Ç –ø–ª—é—Å–æ–º|–ø–ª—é—Å–æ–º –±—É–¥–µ—Ç|–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ–º)',
        r'\b(?:–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫[–∏–æ–∞][–µ–π–º]|—Å–∏—Å—Ç–µ–º–Ω[–æ–∞][–µ–π–º])\s+(?:–º—ã—à–ª–µ–Ω–∏–µ|—Å–∫–ª–∞–¥ —É–º–∞)',
        r'\b(?:–∫–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω|–∫–æ–º–º—É–Ω–∏–∫–∞–±–µ–ª—å–Ω)',
        r'\b(?:–Ω–∞–≤—ã–∫–∏|–æ–ø—ã—Ç)\s+(?:—Ä–∞–±–æ—Ç—ã —Å|–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è|–ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)',
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ï–ô (—É–ª—É—á—à–µ–Ω–Ω—ã–µ)
    RESPONSIBILITY_PATTERNS = [
        r'\b(?:—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞|—Ä–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å|develop|build|create)\b',
        r'\b(?:–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ|–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å|design)\b',
        r'\b(?:–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ|–≤–Ω–µ–¥—Ä–∏—Ç—å|implement|deploy)\b',
        r'\b(?:–ø–æ–¥–¥–µ—Ä–∂–∫–∞|–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å|maintain|support)\s+(?:—Å–∏—Å—Ç–µ–º|–ø—Ä–æ–¥—É–∫—Ç|–ø—Ä–∏–ª–æ–∂–µ–Ω–∏)',
        r'\b(?:–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è|–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å|optimize)\b',
        r'\b(?:—É—á–∞—Å—Ç–∏–µ –≤|participation in)\b',
        r'\b(?:—Ä–∞–±–æ—Ç–∞ —Å|working with)\s+(?:–∫–æ–º–∞–Ω–¥|–¥–∞–Ω–Ω—ã–º|–∫–ª–∏–µ–Ω—Ç)',
        r'\b(?:–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ|collaborate|interaction)\s+(?:—Å|with)',
        r'\b(?:—Å–æ–∑–¥–∞–Ω–∏–µ|—Å–æ–∑–¥–∞–≤–∞—Ç—å)\s+(?:–¥–æ–∫—É–º–µ–Ω—Ç|–æ—Ç—á–µ—Ç|—Ä–µ—à–µ–Ω–∏)',
        r'\b(?:–∞–Ω–∞–ª–∏–∑|–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å|analyze)\s+(?:–¥–∞–Ω–Ω—ã—Ö|–ø—Ä–æ—Ü–µ—Å—Å|—Ç—Ä–µ–±–æ–≤–∞–Ω–∏)',
        r'\b(?:—Å–±–æ—Ä|—Å–æ–±–∏—Ä–∞—Ç—å|collect)\s+(?:—Ç—Ä–µ–±–æ–≤–∞–Ω–∏|–¥–∞–Ω–Ω—ã—Ö|–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏)',
        r'\b(?:–æ–±—É—á–µ–Ω–∏–µ|training)\s+(?:–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π|—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤)',
        r'\b(?:–Ω–∞—Å—Ç—Ä–æ–π–∫–∞|configure|setup)\b',
        r'\b(?:–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è|integrate)\b',
        r'\b(?:—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ|test)\s+(?:—Å–∏—Å—Ç–µ–º|—Ñ—É–Ω–∫—Ü–∏|–ø—Ä–æ—Ü–µ—Å—Å)',
        r'\b(?:you will|–≤–∞–º –ø—Ä–µ–¥—Å—Ç–æ–∏—Ç|—á–µ–º –∑–∞–Ω–∏–º–∞—Ç—å—Å—è)\b',
        r'\b(?:–æ–ø–∏—Å–∞–Ω–∏–µ|–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ|—Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)\b',
        r'\b(?:–∫–æ–Ω—Ç—Ä–æ–ª—å|–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥|–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ)\b',
    ]

    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
    REQUIREMENT_STOP_WORDS = [
        r'\b(?:—Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å|–≤–Ω–µ–¥—Ä—è—Ç—å|–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å|—Å–æ–∑–¥–∞–≤–∞—Ç—å)\b',
        r'\b(?:–ø—Ä–µ–¥—Å—Ç–æ–∏—Ç|–±—É–¥–µ—Ç–µ|–∑–∞–Ω–∏–º–∞—Ç—å—Å—è)\b',
        r'\b(?:—Å–±–æ—Ä|–∞–Ω–∞–ª–∏–∑|—Ä–∞–±–æ—Ç–∞)\s+(?:–∏|—Å|–Ω–∞–¥)',  # –ë–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞–≤—ã–∫–æ–≤
    ]

    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π
    RESPONSIBILITY_STOP_WORDS = [
        r'\b(?:–æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã –æ—Ç|–æ–ø—ã—Ç –æ—Ç)\s+\d+',
        r'\b(?:–≤–ª–∞–¥–µ–Ω–∏–µ|–∑–Ω–∞–Ω–∏–µ)\s+(?:python|java|sql|[–ê-–ØA-Z]\w+)',
        r'\b(?:–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ|—Å—Ç–µ–ø–µ–Ω—å|–¥–∏–ø–ª–æ–º)\b',
    ]

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞."""
        self._compile_patterns()

    def _compile_patterns(self):
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π."""
        self.noise_patterns = [
            re.compile(p, re.IGNORECASE | re.UNICODE)
            for p in self.NOISE_PATTERNS
        ]

        self.req_patterns = [
            re.compile(p, re.IGNORECASE | re.UNICODE)
            for p in self.REQUIREMENT_PATTERNS
        ]

        self.resp_patterns = [
            re.compile(p, re.IGNORECASE | re.UNICODE)
            for p in self.RESPONSIBILITY_PATTERNS
        ]

        self.req_stop_patterns = [
            re.compile(p, re.IGNORECASE | re.UNICODE)
            for p in self.REQUIREMENT_STOP_WORDS
        ]

        self.resp_stop_patterns = [
            re.compile(p, re.IGNORECASE | re.UNICODE)
            for p in self.RESPONSIBILITY_STOP_WORDS
        ]

    def classify(self, text: str) -> ItemType:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞.

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

        Returns:
            ItemType (REQUIREMENT, RESPONSIBILITY, NOISE –∏–ª–∏ UNKNOWN)
        """
        if not text or len(text.strip()) < 10:
            return ItemType.UNKNOWN

        text_clean = text.strip()

        # –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —à—É–º
        if self._is_noise(text_clean):
            return ItemType.NOISE

        # –ü–†–ò–û–†–ò–¢–ï–¢ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ/–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å
        req_score = self._calculate_score(text_clean, self.req_patterns)
        resp_score = self._calculate_score(text_clean, self.resp_patterns)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤
        if self._has_stop_words(text_clean, self.req_stop_patterns):
            req_score = 0

        if self._has_stop_words(text_clean, self.resp_stop_patterns):
            resp_score = 0

        # –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è
        if req_score > resp_score and req_score > 0:
            return ItemType.REQUIREMENT
        elif resp_score > req_score and resp_score > 0:
            return ItemType.RESPONSIBILITY
        else:
            return ItemType.UNKNOWN

    def _is_noise(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —à—É–º–æ–º."""
        for pattern in self.noise_patterns:
            if pattern.search(text):
                return True

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
        if len(text) < 15 or len(text) > 400:
            return True

        # –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö —Å–ª–æ–≤
        marketing_starts = [
            '—É–Ω–∏–∫–∞–ª—å–Ω', '–æ—Ç–ª–∏—á–Ω', '–ø—Ä–µ–∫—Ä–∞—Å–Ω', '–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω',
            '–º—ã –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º', '—á—Ç–æ –º—ã', '–Ω–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è', '–Ω–∞—à–∞ —Ü–µ–ª—å',
            '–µ—Å–ª–∏ –≤—ã', '–µ—Å–ª–∏ —Ç–µ–±–µ', '–∂–¥–µ–º', '–±—É–¥–µ–º —Ä–∞–¥—ã'
        ]

        text_lower = text.lower()
        for word in marketing_starts:
            if text_lower.startswith(word):
                return True

        return False

    def _calculate_score(self, text: str, patterns: List[re.Pattern]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏."""
        score = 0
        for pattern in patterns:
            matches = pattern.findall(text)
            score += len(matches)
        return score

    def _has_stop_words(self, text: str, patterns: List[re.Pattern]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤."""
        for pattern in patterns:
            if pattern.search(text):
                return True
        return False

    def separate_mixed_items(
            self,
            items: List[str]
    ) -> Tuple[List[str], List[str]]:
        """
        –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –Ω–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏.

        Args:
            items: –°–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏)
        """
        requirements = []
        responsibilities = []

        for item in items:
            item_type = self.classify(item)

            if item_type == ItemType.REQUIREMENT:
                requirements.append(item)
            elif item_type == ItemType.RESPONSIBILITY:
                responsibilities.append(item)
            # NOISE –∏ UNKNOWN —ç–ª–µ–º–µ–Ω—Ç—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è

        return requirements, responsibilities
