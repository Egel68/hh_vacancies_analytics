import json
from hh_parser_async import parse_vacancies_async
from processing import VacancyAnalyzer
from visualization import visualize_results


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º"""

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
    config = {
        'query': 'Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫',
        'area': 1,  # –ú–æ—Å–∫–≤–∞
        'max_vacancies': 200,
        'max_concurrent': 15  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    }

    print("=" * 60)
    print(f"–ù–∞—á–∏–Ω–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π: {config['query']}")
    print("=" * 60)

    # 1. –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π
    vacancies = parse_vacancies_async(
        query=config['query'],
        area=config['area'],
        max_vacancies=config['max_vacancies'],
        max_concurrent=config['max_concurrent']
    )

    if not vacancies:
        print("‚ùå –í–∞–∫–∞–Ω—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    with open('result/vacancies_raw.json', 'w', encoding='utf-8') as f:
        json.dump(vacancies, f, ensure_ascii=False, indent=2)

    # 2. –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ...")
    analyzer = VacancyAnalyzer(vacancies)
    df = analyzer.extract_data()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    df.to_csv('result/vacancies_processed.csv', index=False, encoding='utf-8-sig')
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")

    # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 60)
    print(f"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –í–ê–ö–ê–ù–°–ò–Ø–ú: {config['query']}")
    print("=" * 60)
    print(f"–í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(df)}")

    # –ù–∞–≤—ã–∫–∏
    print("\nüìå –¢–æ–ø-20 –Ω–∞–≤—ã–∫–æ–≤:")
    print("-" * 60)
    skills_df = analyzer.analyze_skills()
    print(skills_df.head(20).to_string(index=False))
    skills_df.to_csv('result/skills_analysis.csv', index=False, encoding='utf-8-sig')

    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
    print("\nüìå –¢–æ–ø-20 —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π:")
    print("-" * 60)
    requirements_df = analyzer.analyze_requirements()
    print(requirements_df.head(20).to_string(index=False))
    requirements_df.to_csv('result/requirements_analysis.csv', index=False, encoding='utf-8-sig')

    # –ó–∞—Ä–ø–ª–∞—Ç—ã
    print("\nüí∞ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º:")
    print("-" * 60)
    salary_stats = analyzer.get_salary_stats()
    for key, value in salary_stats.items():
        if isinstance(value, (int, float)):
            print(f"{key}: {value:,.0f}")
        else:
            print(f"{key}: {value}")

    # –û–ø—ã—Ç
    print("\nüëî –¢—Ä–µ–±—É–µ–º—ã–π –æ–ø—ã—Ç:")
    print("-" * 60)
    print(df['experience'].value_counts().to_string())

    # 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    print("\nüìà –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
    visualize_results(analyzer)

    print("\n" + "=" * 60)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 60)
    print("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print("  ‚Ä¢ vacancies_raw.json - —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print("  ‚Ä¢ vacancies_processed.csv - –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print("  ‚Ä¢ skills_analysis.csv - –∞–Ω–∞–ª–∏–∑ –Ω–∞–≤—ã–∫–æ–≤")
    print("  ‚Ä¢ requirements_analysis.csv - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π")
    print("  ‚Ä¢ top_skills.png - –≥—Ä–∞—Ñ–∏–∫ –Ω–∞–≤—ã–∫–æ–≤")
    print("  ‚Ä¢ top_requirements.png - –≥—Ä–∞—Ñ–∏–∫ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π")
    print("  ‚Ä¢ experience_distribution.png - –≥—Ä–∞—Ñ–∏–∫ –æ–ø—ã—Ç–∞")


if __name__ == "__main__":
    main()
